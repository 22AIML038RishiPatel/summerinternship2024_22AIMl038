
# summerinternship2024_22AIMl038

## 13th May 2024

# Summer Internship 2024

## Introduction
 I have done my intenship at Mamo Technolabs as a Python Developer. My internship focuses on enhancing my Python programming skills through hands-on projects and real-world applications. At Mamo Technolabs, I 
 collaborate on innovative software solutions, gaining experience in web development, data analysis, and automation. This opportunity allows me to learn industry best practices and contribute to impactful projects.

# Responsibility
 My responsibilities include developing and maintaining Python-based applications, collaborating with the development team on various projects, writing and optimizing code for performance, and debugging and 
 troubleshooting software issues. This internship allows me to gain practical experience and enhance my skills in a professional setting.

 # Weekly Progress

 ## Week 1: May 13th - May 18th
 - My first task involves extracting company profiles and LinkedIn profiles from the website clutch.co. This entails scraping relevant data, ensuring data accuracy, and addressing any errors that arise during the 
   extraction process. Utilizing Python libraries such as BeautifulSoup and Scrapy.
 - This project will help me hone my web scraping and data handling skills, ensuring that I deliver accurate and reliable results while adhering to best practices in ethical web scraping and data privacy.
    ## Define the Scope:
 - Identify the specific data points needed from Clutch.co, such as company names, profiles, LinkedIn URLs, reviews, ratings, services offered, and contact information.
    ## Set Up the Environment: 
 - Prepare the development environment with the necessary Python libraries and tools, including BeautifulSoup, Scrapy, Requests, and Pandas for data manipulation.

 ## Week 2: May 20th - May 25th
   ## Web Scraping Implementation:
   - Crawling:
         Use Scrapy to navigate through the websiteâ€™s structure, ensuring efficient and comprehensive data collection.
   - Parsing:
         Employ BeautifulSoup to parse the HTML content and extract relevant information.
   ## Data Storage and Management:
   - Store the scraped data in a structured format, such as CSV or a database (e.g., SQLite, MongoDB), ensuring easy access and analysis.
     Regularly update and maintain the dataset to reflect the latest information from Clutch.co.
   - Cross-check the extracted data with source information to ensure accuracy.
   - Use validation techniques to clean and standardize the data, removing duplicates and inconsistencies.

     ![Intenship](https://github.com/22AIML038RishiPatel/summerinternship2024_22AIMl038/assets/120238486/e0185a8a-c373-439c-a828-39d8a529294a)

  ## Week 3: May 27th - Jaun 1st
   - A detailed Google search query was executed to find email addresses of individuals with roles such as CEO, CFO, and HR, specifically in the cyber security field and located in Boston. The search targeted 
     email addresses from domains like gmail.com, hotmail.com, and yahoo.com.
   ## Using an Email Extraction Tool:
   - An email extraction tool or browser extension was utilized to automatically extract email addresses from the search results, identifying a total of 46 email addresses.
   - The tool streamlined the data collection process by automatically scanning and extracting relevant email addresses, reducing the need for manual effort and increasing efficiency.
   - The extracted email addresses were displayed in a sidebar, with options to copy and export the data in various formats (TXT, CSV), facilitating easy integration into further data analysis or outreach 
    activities.

   ![Week_3](https://github.com/22AIML038RishiPatel/summerinternship2024_22AIMl038/assets/120238486/59ab2b96-924b-4202-8135-f9e9906fe1a8)

 ## Week 4: June 3rd - June 8th
   - The code sets up a connection to a PostgreSQL database using credentials stored in environment variables. These variables are loaded using the dotenv library, ensuring secure handling of sensitive 
     information. The connection string is then used to create an engine for database interactions.
   ## Data Fetching and Updating Excel Sheet:
   - The code includes functions to fetch data from specified tables in the database and update an Excel sheet with this data using the xlwings library. The fetch_data_from_database function retrieves all rows nd 
    column names from the selected table, and update_excel_sheet writes this data into the specified Excel sheet.

 ## Week 5: June 10th - June 15th
 ## Uploading Data from Excel to Database:
   - Another function, main_u, reads data from an Excel sheet, processes it into a pandas DataFrame, and uploads it to the specified table in the database. This includes converting column names to lowercase and 
     handling potential exceptions with appropriate error messages using the win32api library.
   - I have start work on project of AI ChatBot for the company. First company give the individual task for the project.  
 






